{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94258fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#this will have extended implementation of basic Policy gradient function and here we will have additional\n",
    "#network function neural network as a critic to judge the actor's actions and improve its odds of balancing the CartPole\n",
    "#this is insipred from open AI article on PPO and below research paper:\n",
    "https://arxiv.org/pdf/1707.06347\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aca965",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#only thing that is special in PPo is that critic sends an advantage function to the actor and then\n",
    "based on the ratio between new policy and old policy ( this is the advantage fxn) we clip the update to a certan range and then run the update\n",
    "this helps in avoiding too much drastic change in network and kind of adds a slow learning ensuring it learns better in time "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
