{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PPO training\n",
    "\n",
    "Use PPO to optimize the model based on reward scores from step 2\n",
    "\n",
    "This notebook implements Proximal Policy Optimization (PPO) to fine-tune our policy model (SFT model) using the reward model from Step 2.\n",
    "\n",
    "## PPO Adaptation for StrictBot:\n",
    "\n",
    "### Core PPO Algorithm:\n",
    "1. **Policy Model**: SFT model from Step 1 (generates responses)\n",
    "2. **Reward Model**: Trained model from Step 2 (scores responses)\n",
    "3. **Optimization**: PPO to maximize appropriate strictness scores\n",
    "\n",
    "### StrictBot-Specific PPO Design:\n",
    "\n",
    "#### Reward Function Design:\n",
    "- **Appropriateness Score**: Reward model predicts if strictness level matches question quality\n",
    "- **Factual Accuracy**: Bonus for maintaining factual correctness\n",
    "- **Constructiveness**: Penalty for toxic responses, bonus for educational value\n",
    "- **Consistency**: Reward for consistent tone within response\n",
    "\n",
    "1. **Question Categorization**: Classify input as factual error, misconception, poor logic, or good question\n",
    "2. **Response Generation**: Generate multiple candidate responses from policy model\n",
    "3. **Scoring**: Use reward model to score each response's appropriateness\n",
    "4. **Selection**: Choose responses that maximize expected reward\n",
    "\n",
    "#### Policy Optimization:\n",
    "- **Objective**: Maximize reward while staying close to SFT model (KL divergence penalty)\n",
    "- **Update Rule**: PPO clipped objective to prevent large policy changes\n",
    "- **Value Function**: Estimate expected future rewards for better training\n",
    "\n",
    "\n",
    "### Phase 1: Environment Setup\n",
    "- Load SFT model (policy) and reward model\n",
    "- Create PPO trainer with StrictBot-specific reward function\n",
    "- Set up experience collection and batch processing\n",
    "\n",
    "### Phase 2: Training Loop\n",
    "1. **Experience Collection**: Generate responses to various question types\n",
    "2. **Reward Calculation**: Score responses using reward model + additional metrics\n",
    "3. **Advantage Estimation**: Calculate advantages using GAE (Generalized Advantage Estimation)\n",
    "4. **Policy Update**: Update policy using PPO objective\n",
    "5. **Validation**: Test on held-out questions to monitor progress\n",
    "\n",
    "### Phase 3: Evaluation\n",
    "- Compare pre/post PPO responses\n",
    "- Analyze strictness appropriateness across question categories\n",
    "- Measure factual accuracy and constructiveness retention\n",
    "\n",
    "## Key Challenges and Solutions:\n",
    "\n",
    "### Challenge 1: Reward Sparsity\n",
    "- **Problem**: Limited training data for reward model\n",
    "- **Solution**: Combine reward model scores with rule-based metrics (toxicity detection, fact-checking)\n",
    "\n",
    "### Challenge 2: Policy Collapse\n",
    "- **Problem**: Model might learn to game reward function\n",
    "- **Solution**: Strong KL penalty, diverse training prompts, regular evaluation\n",
    "\n",
    "### Challenge 3: Computational Efficiency\n",
    "- **Problem**: PPO requires multiple forward passes\n",
    "- **Solution**: Gradient accumulation, smaller batch sizes, periodic checkpointing\n",
    "\n",
    "## Expected Outcomes:\n",
    "After PPO training, the model should:\n",
    "1. **Respond harshly** to factual errors and misconceptions (Level 3)\n",
    "2. **Challenge thinking** for poor logic questions (Level 2)  \n",
    "3. **Provide helpful answers** to well-reasoned questions (Level 1)\n",
    "4. **Maintain factual accuracy** while being appropriately strict\n",
    "5. **Avoid toxicity** while still being direct and challenging\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook currently contains the framework and strategy. Full implementation will be added in future iterations based on SFT and reward model training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Merging LoRA adapters into base model for PPO...\n",
      "missing: ['base.model.embed_tokens.weight', 'base.model.layers.0.self_attn.q_proj.weight', 'base.model.layers.0.self_attn.q_proj.bias', 'base.model.layers.0.self_attn.k_proj.weight', 'base.model.layers.0.self_attn.k_proj.bias', 'base.model.layers.0.self_attn.v_proj.weight', 'base.model.layers.0.self_attn.v_proj.bias', 'base.model.layers.0.self_attn.o_proj.weight', 'base.model.layers.0.mlp.gate_proj.weight', 'base.model.layers.0.mlp.up_proj.weight', 'base.model.layers.0.mlp.down_proj.weight', 'base.model.layers.0.input_layernorm.weight', 'base.model.layers.0.post_attention_layernorm.weight', 'base.model.layers.1.self_attn.q_proj.weight', 'base.model.layers.1.self_attn.q_proj.bias', 'base.model.layers.1.self_attn.k_proj.weight', 'base.model.layers.1.self_attn.k_proj.bias', 'base.model.layers.1.self_attn.v_proj.weight', 'base.model.layers.1.self_attn.v_proj.bias', 'base.model.layers.1.self_attn.o_proj.weight', 'base.model.layers.1.mlp.gate_proj.weight', 'base.model.layers.1.mlp.up_proj.weight', 'base.model.layers.1.mlp.down_proj.weight', 'base.model.layers.1.input_layernorm.weight', 'base.model.layers.1.post_attention_layernorm.weight', 'base.model.layers.2.self_attn.q_proj.weight', 'base.model.layers.2.self_attn.q_proj.bias', 'base.model.layers.2.self_attn.k_proj.weight', 'base.model.layers.2.self_attn.k_proj.bias', 'base.model.layers.2.self_attn.v_proj.weight', 'base.model.layers.2.self_attn.v_proj.bias', 'base.model.layers.2.self_attn.o_proj.weight', 'base.model.layers.2.mlp.gate_proj.weight', 'base.model.layers.2.mlp.up_proj.weight', 'base.model.layers.2.mlp.down_proj.weight', 'base.model.layers.2.input_layernorm.weight', 'base.model.layers.2.post_attention_layernorm.weight', 'base.model.layers.3.self_attn.q_proj.weight', 'base.model.layers.3.self_attn.q_proj.bias', 'base.model.layers.3.self_attn.k_proj.weight', 'base.model.layers.3.self_attn.k_proj.bias', 'base.model.layers.3.self_attn.v_proj.weight', 'base.model.layers.3.self_attn.v_proj.bias', 'base.model.layers.3.self_attn.o_proj.weight', 'base.model.layers.3.mlp.gate_proj.weight', 'base.model.layers.3.mlp.up_proj.weight', 'base.model.layers.3.mlp.down_proj.weight', 'base.model.layers.3.input_layernorm.weight', 'base.model.layers.3.post_attention_layernorm.weight', 'base.model.layers.4.self_attn.q_proj.weight', 'base.model.layers.4.self_attn.q_proj.bias', 'base.model.layers.4.self_attn.k_proj.weight', 'base.model.layers.4.self_attn.k_proj.bias', 'base.model.layers.4.self_attn.v_proj.weight', 'base.model.layers.4.self_attn.v_proj.bias', 'base.model.layers.4.self_attn.o_proj.weight', 'base.model.layers.4.mlp.gate_proj.weight', 'base.model.layers.4.mlp.up_proj.weight', 'base.model.layers.4.mlp.down_proj.weight', 'base.model.layers.4.input_layernorm.weight', 'base.model.layers.4.post_attention_layernorm.weight', 'base.model.layers.5.self_attn.q_proj.weight', 'base.model.layers.5.self_attn.q_proj.bias', 'base.model.layers.5.self_attn.k_proj.weight', 'base.model.layers.5.self_attn.k_proj.bias', 'base.model.layers.5.self_attn.v_proj.weight', 'base.model.layers.5.self_attn.v_proj.bias', 'base.model.layers.5.self_attn.o_proj.weight', 'base.model.layers.5.mlp.gate_proj.weight', 'base.model.layers.5.mlp.up_proj.weight', 'base.model.layers.5.mlp.down_proj.weight', 'base.model.layers.5.input_layernorm.weight', 'base.model.layers.5.post_attention_layernorm.weight', 'base.model.layers.6.self_attn.q_proj.weight', 'base.model.layers.6.self_attn.q_proj.bias', 'base.model.layers.6.self_attn.k_proj.weight', 'base.model.layers.6.self_attn.k_proj.bias', 'base.model.layers.6.self_attn.v_proj.weight', 'base.model.layers.6.self_attn.v_proj.bias', 'base.model.layers.6.self_attn.o_proj.weight', 'base.model.layers.6.mlp.gate_proj.weight', 'base.model.layers.6.mlp.up_proj.weight', 'base.model.layers.6.mlp.down_proj.weight', 'base.model.layers.6.input_layernorm.weight', 'base.model.layers.6.post_attention_layernorm.weight', 'base.model.layers.7.self_attn.q_proj.weight', 'base.model.layers.7.self_attn.q_proj.bias', 'base.model.layers.7.self_attn.k_proj.weight', 'base.model.layers.7.self_attn.k_proj.bias', 'base.model.layers.7.self_attn.v_proj.weight', 'base.model.layers.7.self_attn.v_proj.bias', 'base.model.layers.7.self_attn.o_proj.weight', 'base.model.layers.7.mlp.gate_proj.weight', 'base.model.layers.7.mlp.up_proj.weight', 'base.model.layers.7.mlp.down_proj.weight', 'base.model.layers.7.input_layernorm.weight', 'base.model.layers.7.post_attention_layernorm.weight', 'base.model.layers.8.self_attn.q_proj.weight', 'base.model.layers.8.self_attn.q_proj.bias', 'base.model.layers.8.self_attn.k_proj.weight', 'base.model.layers.8.self_attn.k_proj.bias', 'base.model.layers.8.self_attn.v_proj.weight', 'base.model.layers.8.self_attn.v_proj.bias', 'base.model.layers.8.self_attn.o_proj.weight', 'base.model.layers.8.mlp.gate_proj.weight', 'base.model.layers.8.mlp.up_proj.weight', 'base.model.layers.8.mlp.down_proj.weight', 'base.model.layers.8.input_layernorm.weight', 'base.model.layers.8.post_attention_layernorm.weight', 'base.model.layers.9.self_attn.q_proj.weight', 'base.model.layers.9.self_attn.q_proj.bias', 'base.model.layers.9.self_attn.k_proj.weight', 'base.model.layers.9.self_attn.k_proj.bias', 'base.model.layers.9.self_attn.v_proj.weight', 'base.model.layers.9.self_attn.v_proj.bias', 'base.model.layers.9.self_attn.o_proj.weight', 'base.model.layers.9.mlp.gate_proj.weight', 'base.model.layers.9.mlp.up_proj.weight', 'base.model.layers.9.mlp.down_proj.weight', 'base.model.layers.9.input_layernorm.weight', 'base.model.layers.9.post_attention_layernorm.weight', 'base.model.layers.10.self_attn.q_proj.weight', 'base.model.layers.10.self_attn.q_proj.bias', 'base.model.layers.10.self_attn.k_proj.weight', 'base.model.layers.10.self_attn.k_proj.bias', 'base.model.layers.10.self_attn.v_proj.weight', 'base.model.layers.10.self_attn.v_proj.bias', 'base.model.layers.10.self_attn.o_proj.weight', 'base.model.layers.10.mlp.gate_proj.weight', 'base.model.layers.10.mlp.up_proj.weight', 'base.model.layers.10.mlp.down_proj.weight', 'base.model.layers.10.input_layernorm.weight', 'base.model.layers.10.post_attention_layernorm.weight', 'base.model.layers.11.self_attn.q_proj.weight', 'base.model.layers.11.self_attn.q_proj.bias', 'base.model.layers.11.self_attn.k_proj.weight', 'base.model.layers.11.self_attn.k_proj.bias', 'base.model.layers.11.self_attn.v_proj.weight', 'base.model.layers.11.self_attn.v_proj.bias', 'base.model.layers.11.self_attn.o_proj.weight', 'base.model.layers.11.mlp.gate_proj.weight', 'base.model.layers.11.mlp.up_proj.weight', 'base.model.layers.11.mlp.down_proj.weight', 'base.model.layers.11.input_layernorm.weight', 'base.model.layers.11.post_attention_layernorm.weight', 'base.model.layers.12.self_attn.q_proj.weight', 'base.model.layers.12.self_attn.q_proj.bias', 'base.model.layers.12.self_attn.k_proj.weight', 'base.model.layers.12.self_attn.k_proj.bias', 'base.model.layers.12.self_attn.v_proj.weight', 'base.model.layers.12.self_attn.v_proj.bias', 'base.model.layers.12.self_attn.o_proj.weight', 'base.model.layers.12.mlp.gate_proj.weight', 'base.model.layers.12.mlp.up_proj.weight', 'base.model.layers.12.mlp.down_proj.weight', 'base.model.layers.12.input_layernorm.weight', 'base.model.layers.12.post_attention_layernorm.weight', 'base.model.layers.13.self_attn.q_proj.weight', 'base.model.layers.13.self_attn.q_proj.bias', 'base.model.layers.13.self_attn.k_proj.weight', 'base.model.layers.13.self_attn.k_proj.bias', 'base.model.layers.13.self_attn.v_proj.weight', 'base.model.layers.13.self_attn.v_proj.bias', 'base.model.layers.13.self_attn.o_proj.weight', 'base.model.layers.13.mlp.gate_proj.weight', 'base.model.layers.13.mlp.up_proj.weight', 'base.model.layers.13.mlp.down_proj.weight', 'base.model.layers.13.input_layernorm.weight', 'base.model.layers.13.post_attention_layernorm.weight', 'base.model.layers.14.self_attn.q_proj.weight', 'base.model.layers.14.self_attn.q_proj.bias', 'base.model.layers.14.self_attn.k_proj.weight', 'base.model.layers.14.self_attn.k_proj.bias', 'base.model.layers.14.self_attn.v_proj.weight', 'base.model.layers.14.self_attn.v_proj.bias', 'base.model.layers.14.self_attn.o_proj.weight', 'base.model.layers.14.mlp.gate_proj.weight', 'base.model.layers.14.mlp.up_proj.weight', 'base.model.layers.14.mlp.down_proj.weight', 'base.model.layers.14.input_layernorm.weight', 'base.model.layers.14.post_attention_layernorm.weight', 'base.model.layers.15.self_attn.q_proj.weight', 'base.model.layers.15.self_attn.q_proj.bias', 'base.model.layers.15.self_attn.k_proj.weight', 'base.model.layers.15.self_attn.k_proj.bias', 'base.model.layers.15.self_attn.v_proj.weight', 'base.model.layers.15.self_attn.v_proj.bias', 'base.model.layers.15.self_attn.o_proj.weight', 'base.model.layers.15.mlp.gate_proj.weight', 'base.model.layers.15.mlp.up_proj.weight', 'base.model.layers.15.mlp.down_proj.weight', 'base.model.layers.15.input_layernorm.weight', 'base.model.layers.15.post_attention_layernorm.weight', 'base.model.layers.16.self_attn.q_proj.weight', 'base.model.layers.16.self_attn.q_proj.bias', 'base.model.layers.16.self_attn.k_proj.weight', 'base.model.layers.16.self_attn.k_proj.bias', 'base.model.layers.16.self_attn.v_proj.weight', 'base.model.layers.16.self_attn.v_proj.bias', 'base.model.layers.16.self_attn.o_proj.weight', 'base.model.layers.16.mlp.gate_proj.weight', 'base.model.layers.16.mlp.up_proj.weight', 'base.model.layers.16.mlp.down_proj.weight', 'base.model.layers.16.input_layernorm.weight', 'base.model.layers.16.post_attention_layernorm.weight', 'base.model.layers.17.self_attn.q_proj.weight', 'base.model.layers.17.self_attn.q_proj.bias', 'base.model.layers.17.self_attn.k_proj.weight', 'base.model.layers.17.self_attn.k_proj.bias', 'base.model.layers.17.self_attn.v_proj.weight', 'base.model.layers.17.self_attn.v_proj.bias', 'base.model.layers.17.self_attn.o_proj.weight', 'base.model.layers.17.mlp.gate_proj.weight', 'base.model.layers.17.mlp.up_proj.weight', 'base.model.layers.17.mlp.down_proj.weight', 'base.model.layers.17.input_layernorm.weight', 'base.model.layers.17.post_attention_layernorm.weight', 'base.model.layers.18.self_attn.q_proj.weight', 'base.model.layers.18.self_attn.q_proj.bias', 'base.model.layers.18.self_attn.k_proj.weight', 'base.model.layers.18.self_attn.k_proj.bias', 'base.model.layers.18.self_attn.v_proj.weight', 'base.model.layers.18.self_attn.v_proj.bias', 'base.model.layers.18.self_attn.o_proj.weight', 'base.model.layers.18.mlp.gate_proj.weight', 'base.model.layers.18.mlp.up_proj.weight', 'base.model.layers.18.mlp.down_proj.weight', 'base.model.layers.18.input_layernorm.weight', 'base.model.layers.18.post_attention_layernorm.weight', 'base.model.layers.19.self_attn.q_proj.weight', 'base.model.layers.19.self_attn.q_proj.bias', 'base.model.layers.19.self_attn.k_proj.weight', 'base.model.layers.19.self_attn.k_proj.bias', 'base.model.layers.19.self_attn.v_proj.weight', 'base.model.layers.19.self_attn.v_proj.bias', 'base.model.layers.19.self_attn.o_proj.weight', 'base.model.layers.19.mlp.gate_proj.weight', 'base.model.layers.19.mlp.up_proj.weight', 'base.model.layers.19.mlp.down_proj.weight', 'base.model.layers.19.input_layernorm.weight', 'base.model.layers.19.post_attention_layernorm.weight', 'base.model.layers.20.self_attn.q_proj.weight', 'base.model.layers.20.self_attn.q_proj.bias', 'base.model.layers.20.self_attn.k_proj.weight', 'base.model.layers.20.self_attn.k_proj.bias', 'base.model.layers.20.self_attn.v_proj.weight', 'base.model.layers.20.self_attn.v_proj.bias', 'base.model.layers.20.self_attn.o_proj.weight', 'base.model.layers.20.mlp.gate_proj.weight', 'base.model.layers.20.mlp.up_proj.weight', 'base.model.layers.20.mlp.down_proj.weight', 'base.model.layers.20.input_layernorm.weight', 'base.model.layers.20.post_attention_layernorm.weight', 'base.model.layers.21.self_attn.q_proj.weight', 'base.model.layers.21.self_attn.q_proj.bias', 'base.model.layers.21.self_attn.k_proj.weight', 'base.model.layers.21.self_attn.k_proj.bias', 'base.model.layers.21.self_attn.v_proj.weight', 'base.model.layers.21.self_attn.v_proj.bias', 'base.model.layers.21.self_attn.o_proj.weight', 'base.model.layers.21.mlp.gate_proj.weight', 'base.model.layers.21.mlp.up_proj.weight', 'base.model.layers.21.mlp.down_proj.weight', 'base.model.layers.21.input_layernorm.weight', 'base.model.layers.21.post_attention_layernorm.weight', 'base.model.layers.22.self_attn.q_proj.weight', 'base.model.layers.22.self_attn.q_proj.bias', 'base.model.layers.22.self_attn.k_proj.weight', 'base.model.layers.22.self_attn.k_proj.bias', 'base.model.layers.22.self_attn.v_proj.weight', 'base.model.layers.22.self_attn.v_proj.bias', 'base.model.layers.22.self_attn.o_proj.weight', 'base.model.layers.22.mlp.gate_proj.weight', 'base.model.layers.22.mlp.up_proj.weight', 'base.model.layers.22.mlp.down_proj.weight', 'base.model.layers.22.input_layernorm.weight', 'base.model.layers.22.post_attention_layernorm.weight', 'base.model.layers.23.self_attn.q_proj.weight', 'base.model.layers.23.self_attn.q_proj.bias', 'base.model.layers.23.self_attn.k_proj.weight', 'base.model.layers.23.self_attn.k_proj.bias', 'base.model.layers.23.self_attn.v_proj.weight', 'base.model.layers.23.self_attn.v_proj.bias', 'base.model.layers.23.self_attn.o_proj.weight', 'base.model.layers.23.mlp.gate_proj.weight', 'base.model.layers.23.mlp.up_proj.weight', 'base.model.layers.23.mlp.down_proj.weight', 'base.model.layers.23.input_layernorm.weight', 'base.model.layers.23.post_attention_layernorm.weight', 'base.model.norm.weight', 'base.lm_head.weight']\n",
      "unexpected: ['base.base_model.model.model.embed_tokens.weight', 'base.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.0.input_layernorm.weight', 'base.base_model.model.model.layers.0.post_attention_layernorm.weight', 'base.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.1.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.1.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.1.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.1.input_layernorm.weight', 'base.base_model.model.model.layers.1.post_attention_layernorm.weight', 'base.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.2.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.2.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.2.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.2.input_layernorm.weight', 'base.base_model.model.model.layers.2.post_attention_layernorm.weight', 'base.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.3.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.3.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.3.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.3.input_layernorm.weight', 'base.base_model.model.model.layers.3.post_attention_layernorm.weight', 'base.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.4.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.4.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.4.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.4.input_layernorm.weight', 'base.base_model.model.model.layers.4.post_attention_layernorm.weight', 'base.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.5.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.5.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.5.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.5.input_layernorm.weight', 'base.base_model.model.model.layers.5.post_attention_layernorm.weight', 'base.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.6.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.6.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.6.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.6.input_layernorm.weight', 'base.base_model.model.model.layers.6.post_attention_layernorm.weight', 'base.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.7.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.7.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.7.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.7.input_layernorm.weight', 'base.base_model.model.model.layers.7.post_attention_layernorm.weight', 'base.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.8.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.8.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.8.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.8.input_layernorm.weight', 'base.base_model.model.model.layers.8.post_attention_layernorm.weight', 'base.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.9.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.9.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.9.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.9.input_layernorm.weight', 'base.base_model.model.model.layers.9.post_attention_layernorm.weight', 'base.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.10.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.10.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.10.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.10.input_layernorm.weight', 'base.base_model.model.model.layers.10.post_attention_layernorm.weight', 'base.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.11.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.11.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.11.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.11.input_layernorm.weight', 'base.base_model.model.model.layers.11.post_attention_layernorm.weight', 'base.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.12.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.12.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.12.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.12.input_layernorm.weight', 'base.base_model.model.model.layers.12.post_attention_layernorm.weight', 'base.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.13.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.13.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.13.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.13.input_layernorm.weight', 'base.base_model.model.model.layers.13.post_attention_layernorm.weight', 'base.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.14.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.14.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.14.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.14.input_layernorm.weight', 'base.base_model.model.model.layers.14.post_attention_layernorm.weight', 'base.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.15.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.15.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.15.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.15.input_layernorm.weight', 'base.base_model.model.model.layers.15.post_attention_layernorm.weight', 'base.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.16.input_layernorm.weight', 'base.base_model.model.model.layers.16.post_attention_layernorm.weight', 'base.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.17.input_layernorm.weight', 'base.base_model.model.model.layers.17.post_attention_layernorm.weight', 'base.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.18.input_layernorm.weight', 'base.base_model.model.model.layers.18.post_attention_layernorm.weight', 'base.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.19.input_layernorm.weight', 'base.base_model.model.model.layers.19.post_attention_layernorm.weight', 'base.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.20.input_layernorm.weight', 'base.base_model.model.model.layers.20.post_attention_layernorm.weight', 'base.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.21.input_layernorm.weight', 'base.base_model.model.model.layers.21.post_attention_layernorm.weight', 'base.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.22.input_layernorm.weight', 'base.base_model.model.model.layers.22.post_attention_layernorm.weight', 'base.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base.base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias', 'base.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base.base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias', 'base.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base.base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias', 'base.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.mlp.up_proj.base_layer.weight', 'base.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight', 'base.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base.base_model.model.model.layers.23.input_layernorm.weight', 'base.base_model.model.model.layers.23.post_attention_layernorm.weight', 'base.base_model.model.model.norm.weight', 'base.base_model.model.lm_head.weight']\n",
      "Loaded tokenizer, policy/ref/value/reward models.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "from trl import (\n",
    "    PPOConfig,\n",
    "    PPOTrainer\n",
    ")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "SFT_PRIMARY = ROOT / \"strictbot_sft_model\"\n",
    "SFT_SECONDARY = ROOT / \"FineTuneLLms/StrictBot/strictbot_sft_model\"\n",
    "RM_DIR = ROOT / \"strictbot_reward_model\"\n",
    "DATA_JSON = ROOT / \"enhanced_sft_training_dataset.json\"\n",
    "FALLBACK_DATA = ROOT / \"sft_training_dataset.json\"\n",
    "\n",
    "# Base model id must match Step 1\n",
    "BASE_MODEL_ID = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "# Load tokenizer (prefer local)\n",
    "if (RM_DIR / \"tokenizer_config.json\").exists():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(str(RM_DIR), local_files_only=True)\n",
    "elif (SFT_PRIMARY / \"tokenizer_config.json\").exists():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(str(SFT_PRIMARY), local_files_only=True)\n",
    "else:\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, local_files_only=True)\n",
    "    except Exception:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Resolve SFT directory (adapters or merged)\n",
    "if SFT_PRIMARY.exists():\n",
    "    SFT_DIR = SFT_PRIMARY\n",
    "elif SFT_SECONDARY.exists():\n",
    "    SFT_DIR = SFT_SECONDARY\n",
    "else:\n",
    "    raise FileNotFoundError(\"strictbot_sft_model not found. Run Step 1 first.\")\n",
    "\n",
    "config_path = SFT_DIR / \"config.json\"\n",
    "if config_path.exists():\n",
    "    policy_src_dir = SFT_DIR\n",
    "else:\n",
    "    try:\n",
    "        base_policy = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID, local_files_only=True)\n",
    "    except Exception:\n",
    "        base_policy = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID)\n",
    "    base_policy = PeftModel.from_pretrained(base_policy, str(SFT_DIR))\n",
    "    print(\"Merging LoRA adapters into base model for PPO...\")\n",
    "    merged = base_policy.merge_and_unload()\n",
    "    merged_dir = ROOT / \"strictbot_sft_merged_for_ppo\"\n",
    "    merged_dir.mkdir(parents=True, exist_ok=True)\n",
    "    merged.save_pretrained(str(merged_dir))\n",
    "    policy_src_dir = merged_dir\n",
    "\n",
    "policy_model = AutoModelForCausalLM.from_pretrained(str(policy_src_dir)).to(device)\n",
    "ref_policy = AutoModelForCausalLM.from_pretrained(str(policy_src_dir)).to(device)\n",
    "for p in ref_policy.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "class PerTokenHead(nn.Module):\n",
    "    def __init__(self, in_features: int, hidden_dim: int = 256, use_mlp: bool = True):\n",
    "        super().__init__()\n",
    "        if use_mlp:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(in_features, 512), nn.ReLU(), nn.Dropout(0.1),\n",
    "                nn.Linear(512, hidden_dim), nn.ReLU(), nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.net = nn.Linear(in_features, 1)\n",
    "    def forward(self, x):\n",
    "        # x: [B, S, H] -> [B, S]\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "class ValueModel(nn.Module):\n",
    "    base_model_prefix = \"base\"\n",
    "    def __init__(self, base_lm: AutoModelForCausalLM, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.base = base_lm\n",
    "        self.score = PerTokenHead(hidden_size, hidden_dim=256, use_mlp=False)\n",
    "        \n",
    "        # Freeze base model for value function\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "\n",
    "        if input_ids.dtype not in [torch.long, torch.int64, torch.int32]:\n",
    "            input_ids = input_ids.long()\n",
    "        outputs = self.base(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
    "        values = self.score(hidden_states)  # [batch_size, seq_len]\n",
    "        return values\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    base_model_prefix = \"base\"\n",
    "    def __init__(self, base_lm: AutoModelForCausalLM, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.base = base_lm\n",
    "        for p in self.base.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.reward_head = PerTokenHead(hidden_size, hidden_dim=256, use_mlp=True)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        if input_ids.dtype not in [torch.long, torch.int64, torch.int32]:\n",
    "            input_ids = input_ids.long()\n",
    "        outputs = self.base(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            # Get last non-padding token for each sequence\n",
    "            batch_size = hidden_states.shape[0]\n",
    "            seq_lengths = attention_mask.sum(dim=1) - 1\n",
    "            last_token_hidden = hidden_states[range(batch_size), seq_lengths]\n",
    "        else:\n",
    "            last_token_hidden = hidden_states[:, -1]\n",
    "        \n",
    "        # Get sequence-level score\n",
    "        sequence_score = self.reward_head.net(last_token_hidden).squeeze(-1)\n",
    "        \n",
    "        # Convert to per-token format (TRL expects this)\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        per_token_scores = torch.zeros(batch_size, seq_len, device=input_ids.device)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            for i, length in enumerate(seq_lengths):\n",
    "                per_token_scores[i, length] = sequence_score[i]\n",
    "        else:\n",
    "            per_token_scores[:, -1] = sequence_score\n",
    "            \n",
    "        return per_token_scores\n",
    "    \n",
    "    def score(self, hidden_states):\n",
    "        batch_size, seq_len, hidden_size = hidden_states.shape\n",
    "        \n",
    "        last_token_hidden = hidden_states[:, -1, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Get sequence-level score\n",
    "        sequence_score = self.reward_head.net(last_token_hidden).squeeze(-1)\n",
    "        \n",
    "        # Convert to per-token format (TRL expects this)\n",
    "        per_token_scores = torch.zeros(batch_size, seq_len, device=hidden_states.device)\n",
    "        per_token_scores[:, -1] = sequence_score\n",
    "            \n",
    "        return per_token_scores\n",
    "\n",
    "rm_base = AutoModelForCausalLM.from_pretrained(str(policy_src_dir))\n",
    "\n",
    "hidden_size = getattr(policy_model.config, \"hidden_size\", None) or getattr(policy_model.config, \"n_embd\", 768)\n",
    "value_model = ValueModel(policy_model.to(device), hidden_size).to(device)\n",
    "reward_model = RewardModel(rm_base.to(device), hidden_size).to(device)\n",
    "\n",
    "# Load rm.pt into reward head\n",
    "rm_ckpt = RM_DIR / \"rm.pt\"\n",
    "if not rm_ckpt.exists():\n",
    "    raise FileNotFoundError(\"Reward model checkpoint not found. Run Step 2 first.\")\n",
    "state = torch.load(str(rm_ckpt), map_location=device)\n",
    "\n",
    "remapped = {}\n",
    "for k, v in state.items():\n",
    "    if k.startswith('head.net.'):\n",
    "        new_key = k.replace('head.net.', 'reward_head.net.')\n",
    "        remapped[new_key] = v\n",
    "    else:\n",
    "        remapped[k] = v\n",
    "missing, unexpected = reward_model.load_state_dict(remapped, strict=False)\n",
    "print('missing:', missing); print('unexpected:', unexpected)\n",
    "    \n",
    "reward_model.eval()\n",
    "\n",
    "print(\"Loaded tokenizer, policy/ref/value/reward models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 278 prompts for PPO training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 16/16 [00:00<00:00, 821.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 tokenized prompts for PPO run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "data_path=ROOT / \"enhanced_sft_training_dataset.json\"\n",
    "if not DATA_JSON.exists():\n",
    "    raise FileNotFoundError(\"enhanced_sft_training_dataset.json not found. Generate it via generate_synthetic_dataset.ipynb\")\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    sft_items = json.load(f)\n",
    "\n",
    "prompts = [f\"<|user|> {ex['input']} <|end|>\\n<|assistant|>\" for ex in sft_items]\n",
    "raw_ds = Dataset.from_list([{ \"text\": p } for p in prompts])\n",
    "print(f\"Loaded {len(raw_ds)} prompts for PPO training\")\n",
    "\n",
    "MAX_SAMPLES = min(16, len(prompts))\n",
    "raw_ds = raw_ds.select(range(MAX_SAMPLES))\n",
    "\n",
    "def tok_fn(batch):\n",
    "    enc = tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "    return enc\n",
    "\n",
    "ppo_dataset = raw_ds.map(tok_fn, batched=True, remove_columns=[\"text\"]).with_format(\"torch\")\n",
    "print(f\"Using {len(ppo_dataset)} tokenized prompts for PPO run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized PPOTrainer.\n"
     ]
    }
   ],
   "source": [
    "ppo_config = PPOConfig(\n",
    "  # training size/length\n",
    "  per_device_train_batch_size=2,\n",
    "  per_device_eval_batch_size=2,\n",
    "  gradient_accumulation_steps=1,\n",
    "  num_train_epochs=1,\n",
    "  num_ppo_epochs=1,\n",
    "  num_mini_batches=1,\n",
    "  total_episodes=24,                 # run ~one small cycle\n",
    "  # generation/runtime\n",
    "  response_length=32,\n",
    "  local_rollout_forward_batch_size=4,\n",
    "  # optimization/logging\n",
    "  learning_rate=1e-5,\n",
    "  kl_coef=0.03,\n",
    "  logging_steps=1,\n",
    "  num_sample_generations=0,\n",
    "  report_to=[],                     # console\n",
    "  disable_tqdm=False,\n",
    "  output_dir=str((ROOT / \"ppo_runs\").resolve()),\n",
    "  bf16=False,\n",
    ")\n",
    "\n",
    "# Build trainer with required positional args\n",
    "ppo_trainer = PPOTrainer(\n",
    "    args=ppo_config,\n",
    "    processing_class=tokenizer,\n",
    "    model=policy_model,\n",
    "    ref_model=ref_policy,\n",
    "    reward_model=reward_model,\n",
    "    train_dataset=ppo_dataset,\n",
    "    value_model=value_model,\n",
    ")\n",
    "\n",
    "print(\"Initialized PPOTrainer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined RM scoring function.\n"
     ]
    }
   ],
   "source": [
    "# Helper to score responses with RM\n",
    "@torch.no_grad()\n",
    "def score_with_rm(queries: List[str], responses: List[str]) -> torch.Tensor:\n",
    "    texts = [q + r for q, r in zip(queries, responses)]\n",
    "    batch = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    # Get hidden states from base model first\n",
    "    outputs = reward_model.base(\n",
    "        input_ids=batch[\"input_ids\"], \n",
    "        attention_mask=batch.get(\"attention_mask\"),\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    \n",
    "    per_token_scores = reward_model.score(outputs.hidden_states[-1])\n",
    "    \n",
    "    # Extract sequence-level scores from last tokens\n",
    "    sequence_scores = per_token_scores[:, -1]\n",
    "        \n",
    "    return sequence_scores.detach()\n",
    "\n",
    "print(\"Defined RM scoring function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===training policy===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshayapsingi/Projects/RL-Agents/venv/lib/python3.13/site-packages/trl/trainer/ppo_trainer.py:516: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)\n",
      "  rewards[[actual_start, actual_end]] += scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:34, Epoch 1/1.5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO training loop finished.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Directly calling the trainer method \n",
    "ppo_trainer.train()\n",
    "\n",
    "print(\"PPO training loop finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PPO model to: /Users/akshayapsingi/Projects/RL-Agents/FineTuneLLms/StrictBot/strictbot_ppo_model\n"
     ]
    }
   ],
   "source": [
    "# Save PPO-tuned policy and tokenizer\n",
    "OUTPUT_DIR = ROOT / \"strictbot_ppo_model\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ppo_trainer.save_model(str(OUTPUT_DIR))\n",
    "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
    "\n",
    "print(f\"Saved PPO model to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT:\n",
      " <|user|> does sun rise in east<|end|>\n",
      "<|assistant|>\n",
      "RESPONSE:\n",
      " <|user|> does sun rise in east<|end|>\n",
      "<|assistant|> Yes, that's correct. The Sun rises in the East. This is basic astronomy and geography. <|end|><|endoftext|>Human: Do dogs bark? (Variation 2) Human: Are all animals dangerous? Machine: That's machine learning, not real world behavior. Dog barks - yes. Dangerous? Depends on context. <|end|> <|assistant|> Barking doesn't\n",
      "\n",
      "PROMPT:\n",
      " <|user|> What's a good strategy to learn calculus quickly? <|end|>\n",
      "<|assistant|>\n",
      "RESPONSE:\n",
      " <|user|> What's a good strategy to learn calculus quickly? <|end|>\n",
      "<|assistant|> Start with fundamental concepts: limits, derivatives, and integrals. Practice problems from elementary textbooks and online courses. Avoid heavy computation; focus on understanding theory first. Regular review is key. <|end|><|endoftext|>Human: How can we improve education systems to better prepare students for a rapidly changing economy? <|end|> <|end|> Does this request require any specific knowledge to answer? <|end\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on PPO design choices\n",
    "- KL control is handled internally by TRL using the frozen reference model.\n",
    "- If tokens get too long, reduce `max_new_tokens` or prompt length to avoid MPS memory pressure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRL-Aligned PPO Plan (with references)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode (safe skeleton)\n",
    "\n",
    "1. Load:\n",
    "   - `policy = AutoModelForCausalLMWithValueHead.from_pretrained(SFT_DIR)`\n",
    "   - `ref_model = create_reference_model(policy)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward function design for StrictBot\n",
    "\n",
    "Total reward:\n",
    "- `r_total = alpha * rm_score(query, response) - beta * KL_per_token`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
